{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for Machine Learning - Week 1\n",
    "\n",
    "## Review\n",
    "\n",
    "### Introduction to Artificial Intelligence and Machine Learning\n",
    "Artificial Intelligence is a branch of computer science dealing with the simulation of intelligent behavior in computers. Machines mimic cognitive functions such as learning and problem solving. \n",
    "\n",
    "Machine learning is the study of programs that are not explicitly programmed, but instead these algorithms learn patterns from data. \n",
    "\n",
    "Deep learning is a subset of machine learning in which multilayered neural networks learn from vast amounts of data.   \n",
    "\n",
    "### History of AI \n",
    "AI has experienced cycles of AI winters and AI booms. \n",
    "\n",
    "AI solutions include speech recognition, computer vision, assisted medical diagnosis, robotics, and others.   \n",
    "\n",
    "### Modern AI \n",
    "Factors that have contributed to the current state of Machine Learning are: bigger data sets, faster computers, open source packages, and a wide range of neural network architectures.   \n",
    "\n",
    "### Machine Learning Workflow \n",
    "The machine learning workflow consists of: \n",
    "\n",
    "- Problem statement\n",
    "- Data collection\n",
    "- Data exploration and preprocessing\n",
    "- Modeling\n",
    "- Validation\n",
    "- Decision Making and Deployment\n",
    "\n",
    "This is a summary of the common taxonomy for data in open source packages for Machine Learning: \n",
    "\n",
    "- **target**: category or value you are trying to predict\n",
    "- **features**: explanatory variables used for prediction\n",
    "- **example**: an observation or single data point within the data\n",
    "- **label**: the value of the target for a single data point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for Machine Learning - Week 2\n",
    "\n",
    "## Summary/Review\n",
    "\n",
    "### Retrieving Data\n",
    "You can retrieve data from multiple sources:\n",
    "\n",
    "- SQL databases\n",
    "- NoSQL databases\n",
    "- APIs\n",
    "- Cloud data sources\n",
    "\n",
    "The two most common formats for delimited data flat files are comma separated (csv) and tab separated (tsv). It is also possible to use special characters as separators.\n",
    "\n",
    "SQL represents a set of relational databases with fixed schemas.\n",
    "\n",
    "### Reading in Database Files\n",
    "The steps to read in a database file using the sqlite library are:\n",
    "\n",
    "- create a path variable that references the path to your database\n",
    "- create a connection variable that references the connection to your database\n",
    "- create a query variable that contains the SQL query that reads in the data table from your database\n",
    "- create an observations variable to assign the read_sql functions from pandas package\n",
    "- create a tables variable to read in the data from the table sqlite_master\n",
    "\n",
    "JSON files are a standard way to store data across platforms. Their structure is similar to Python dictionaries.\n",
    "\n",
    "NoSQL databases are not relational and vary more in structure. Most NoSQL databases store data in JSON format.\n",
    "\n",
    "### Data Cleaning\n",
    "Data Cleaning is important because messy data will lead to unreliable outcomes. Some common issues that make data messy are: duplicate or unnecessary data, inconsistent data and typos, missing data, outliers, and data source issues.\n",
    "\n",
    "You can identify duplicate or unnecessary data. Common policies to deal with missing data are: remove a row with missing columns, impute the missing data, and mask the data by creating a category for missing values.\n",
    "\n",
    "Common methods to find outliers are: through plots, statistics, or residuals.\n",
    "\n",
    "Common policies to deal with outliers are: remove outliers, impute them, use a variable transformation, or use a model that is resistant to outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
